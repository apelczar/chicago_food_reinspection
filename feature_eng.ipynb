{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "- If we want to keep our prediction binary, we should change all 'Pass w/ Conditions' in the `results_re` field to 'Pass'.\n",
    "- We should also make this field numeric, with Fail as 1 and Pass as 0 (as 'Fail' is the event we are trying to predict). I think we can add both of these to the `data_prep` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questions to discuss:__\n",
    "- __Shuffling during train/test split__: When we do our train/test split, should we sort our data by inspection date first? I know this matters for time series data (where we'd want to avoid leakage of future data into the past), but not sure how much it matters here, where the inspections are generally distinct establishments. Below I did sort the data, and didn't shuffle during the train/test split, but would like your thoughts on whether this matters.\n",
    "- __Word frequency threshold__: In our HW 2, we only included in our vocab words that appeared at least 1000 times in the entire corpus. We'll need to decide what threshold we want to use. I used 1000 below, and also listed the vocab counts at different thresholds.\n",
    "- __Pipeline operations__: What kinds of additional cleaning steps should we perform in our pipeline? Right now, we're just converting words to lower case and splitting them with a tokenizer. Other possible steps include removing stop words and lemmatizing (https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/). I'd recommend we go to Amitabh's office hours to get his thoughts on an appropriate 'good practice' pipeline.\n",
    "- __Relative vs. absolute frequencies for BOW__: In our HW, we implemented BOW with relative frequencies, but I think for our purposes absolute frequencies make more sense, as more words/longer comments can mean more violations. Do you think this makes sense?\n",
    "- __Choice of n for ngrams__: I made an initial choice of 2, which seemed reasonable to me. Would like your thoughts on this, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('initial_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    id_orig              name  license facility_type  date_orig  \\\n",
       "10  1989768            VOLARE  2141813    Restaurant 2017-02-27   \n",
       "13  1632809            VOLARE  2141813    Restaurant 2016-03-08   \n",
       "32  1448101  STREETERS TAVERN     8864        TAVERN 2015-12-01   \n",
       "36  2453925       MISS SAIGON  2699550    Restaurant 2020-10-28   \n",
       "39  2352289       MISS SAIGON  2699550    Restaurant 2019-11-25   \n",
       "\n",
       "   inspection_type_orig results_orig  \\\n",
       "10              Canvass         Fail   \n",
       "13              Canvass         Fail   \n",
       "32            Complaint         Fail   \n",
       "36              Canvass         Fail   \n",
       "39              License         Fail   \n",
       "\n",
       "                                      violations_orig    id_re    date_re  \\\n",
       "10  11. ADEQUATE NUMBER, CONVENIENT, ACCESSIBLE, D...  1989902 2017-03-01   \n",
       "13  16. FOOD PROTECTED DURING STORAGE, PREPARATION...  1734225 2016-03-15   \n",
       "32  16. FOOD PROTECTED DURING STORAGE, PREPARATION...  1448119 2015-12-11   \n",
       "36  58. ALLERGEN TRAINING AS REQUIRED - Comments: ...  2456264 2020-11-05   \n",
       "39  5. PROCEDURES FOR RESPONDING TO VOMITING AND D...  2352403 2019-11-27   \n",
       "\n",
       "            results_re  time_between  \n",
       "10                Pass            -2  \n",
       "13                Pass            -7  \n",
       "32                Pass           -10  \n",
       "36                Pass            -8  \n",
       "39  Pass w/ Conditions            -2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_orig</th>\n      <th>name</th>\n      <th>license</th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>id_re</th>\n      <th>date_re</th>\n      <th>results_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>1989768</td>\n      <td>VOLARE</td>\n      <td>2141813</td>\n      <td>Restaurant</td>\n      <td>2017-02-27</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>11. ADEQUATE NUMBER, CONVENIENT, ACCESSIBLE, D...</td>\n      <td>1989902</td>\n      <td>2017-03-01</td>\n      <td>Pass</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1632809</td>\n      <td>VOLARE</td>\n      <td>2141813</td>\n      <td>Restaurant</td>\n      <td>2016-03-08</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>16. FOOD PROTECTED DURING STORAGE, PREPARATION...</td>\n      <td>1734225</td>\n      <td>2016-03-15</td>\n      <td>Pass</td>\n      <td>-7</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>1448101</td>\n      <td>STREETERS TAVERN</td>\n      <td>8864</td>\n      <td>TAVERN</td>\n      <td>2015-12-01</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>16. FOOD PROTECTED DURING STORAGE, PREPARATION...</td>\n      <td>1448119</td>\n      <td>2015-12-11</td>\n      <td>Pass</td>\n      <td>-10</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2453925</td>\n      <td>MISS SAIGON</td>\n      <td>2699550</td>\n      <td>Restaurant</td>\n      <td>2020-10-28</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>58. ALLERGEN TRAINING AS REQUIRED - Comments: ...</td>\n      <td>2456264</td>\n      <td>2020-11-05</td>\n      <td>Pass</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2352289</td>\n      <td>MISS SAIGON</td>\n      <td>2699550</td>\n      <td>Restaurant</td>\n      <td>2019-11-25</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>5. PROCEDURES FOR RESPONDING TO VOMITING AND D...</td>\n      <td>2352403</td>\n      <td>2019-11-27</td>\n      <td>Pass w/ Conditions</td>\n      <td>-2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Pass w/ Conditions' to 'Pass', and change target to 0/1 numeric\n",
    "results_dict = {'Pass': 0, 'Fail': 1}\n",
    "df['results_re'] = df['results_re'].str.replace('Pass w/ Conditions', 'Pass')\n",
    "df['results_re'] = df['results_re'].apply(lambda x: results_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into feature & target, and then into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by inspection date\n",
    "# Training set will include initial 80% of inspections\n",
    "sorted_df = df.sort_values(by=['date_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       id_orig                          name  license  facility_type  \\\n",
       "236038  104236                    TEMPO CAFE    80916     Restaurant   \n",
       "494289   67738        MICHAEL'S ON MAIN CAFE  2008948     Restaurant   \n",
       "492554  120271  IZUMI SUSHI BAR & RESTAURANT  1357260     Restaurant   \n",
       "97666   118297     MAXWELL STREET DEPOT INC.    18135     Restaurant   \n",
       "290030   67741                         CITGO  2013296  Grocery Store   \n",
       "\n",
       "        date_orig inspection_type_orig results_orig  \\\n",
       "236038 2010-01-04              Canvass         Fail   \n",
       "494289 2010-01-04              License         Fail   \n",
       "492554 2010-01-05            Complaint         Fail   \n",
       "97666  2010-01-05            Complaint         Fail   \n",
       "290030 2010-01-05              License         Fail   \n",
       "\n",
       "                                          violations_orig   id_re    date_re  \\\n",
       "236038  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  104243 2010-01-12   \n",
       "494289  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  124279 2010-01-19   \n",
       "492554  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  120289 2010-01-13   \n",
       "97666   18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  118308 2010-01-12   \n",
       "290030  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...  176270 2010-02-17   \n",
       "\n",
       "        results_re  time_between  \n",
       "236038           0            -8  \n",
       "494289           0           -15  \n",
       "492554           0            -8  \n",
       "97666            0            -7  \n",
       "290030           0           -43  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_orig</th>\n      <th>name</th>\n      <th>license</th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>id_re</th>\n      <th>date_re</th>\n      <th>results_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>236038</th>\n      <td>104236</td>\n      <td>TEMPO CAFE</td>\n      <td>80916</td>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>104243</td>\n      <td>2010-01-12</td>\n      <td>0</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>494289</th>\n      <td>67738</td>\n      <td>MICHAEL'S ON MAIN CAFE</td>\n      <td>2008948</td>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>124279</td>\n      <td>2010-01-19</td>\n      <td>0</td>\n      <td>-15</td>\n    </tr>\n    <tr>\n      <th>492554</th>\n      <td>120271</td>\n      <td>IZUMI SUSHI BAR &amp; RESTAURANT</td>\n      <td>1357260</td>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>120289</td>\n      <td>2010-01-13</td>\n      <td>0</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>97666</th>\n      <td>118297</td>\n      <td>MAXWELL STREET DEPOT INC.</td>\n      <td>18135</td>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>118308</td>\n      <td>2010-01-12</td>\n      <td>0</td>\n      <td>-7</td>\n    </tr>\n    <tr>\n      <th>290030</th>\n      <td>67741</td>\n      <td>CITGO</td>\n      <td>2013296</td>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n      <td>176270</td>\n      <td>2010-02-17</td>\n      <td>0</td>\n      <td>-43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['results_re']\n",
    "target = sorted_df[target_col]\n",
    "\n",
    "cols_to_exclude = ['name', 'id_orig', 'id_re', 'license']\n",
    "feature_cols = [col for col in sorted_df.columns if (col not in cols_to_exclude and col not in target_col)]\n",
    "features = sorted_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        results_re\n",
       "236038           0\n",
       "494289           0\n",
       "492554           0\n",
       "97666            0\n",
       "290030           0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>results_re</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>236038</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>494289</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>492554</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97666</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>290030</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        facility_type  date_orig inspection_type_orig results_orig  \\\n",
       "236038     Restaurant 2010-01-04              Canvass         Fail   \n",
       "494289     Restaurant 2010-01-04              License         Fail   \n",
       "492554     Restaurant 2010-01-05            Complaint         Fail   \n",
       "97666      Restaurant 2010-01-05            Complaint         Fail   \n",
       "290030  Grocery Store 2010-01-05              License         Fail   \n",
       "\n",
       "                                          violations_orig    date_re  \\\n",
       "236038  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "494289  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-19   \n",
       "492554  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-13   \n",
       "97666   18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "290030  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -... 2010-02-17   \n",
       "\n",
       "        time_between  \n",
       "236038            -8  \n",
       "494289           -15  \n",
       "492554            -8  \n",
       "97666             -7  \n",
       "290030           -43  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>date_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>236038</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-12</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>494289</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-19</td>\n      <td>-15</td>\n    </tr>\n    <tr>\n      <th>492554</th>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-13</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>97666</th>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-12</td>\n      <td>-7</td>\n    </tr>\n    <tr>\n      <th>290030</th>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n      <td>2010-02-17</td>\n      <td>-43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't shuffle data before splitting\n",
    "train_feat, test_feat, train_targ, test_targ = train_test_split(features, target, test_size=0.2,\n",
    "                                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        facility_type  date_orig inspection_type_orig results_orig  \\\n",
       "236038     Restaurant 2010-01-04              Canvass         Fail   \n",
       "494289     Restaurant 2010-01-04              License         Fail   \n",
       "492554     Restaurant 2010-01-05            Complaint         Fail   \n",
       "97666      Restaurant 2010-01-05            Complaint         Fail   \n",
       "290030  Grocery Store 2010-01-05              License         Fail   \n",
       "\n",
       "                                          violations_orig    date_re  \\\n",
       "236038  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "494289  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-19   \n",
       "492554  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-13   \n",
       "97666   18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "290030  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -... 2010-02-17   \n",
       "\n",
       "        time_between  \n",
       "236038            -8  \n",
       "494289           -15  \n",
       "492554            -8  \n",
       "97666             -7  \n",
       "290030           -43  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>date_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>236038</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-12</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>494289</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-19</td>\n      <td>-15</td>\n    </tr>\n    <tr>\n      <th>492554</th>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-13</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>97666</th>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-12</td>\n      <td>-7</td>\n    </tr>\n    <tr>\n      <th>290030</th>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n      <td>2010-02-17</td>\n      <td>-43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8.27% reinspections fail in training set\n"
     ]
    }
   ],
   "source": [
    "pct_fail = len(train_targ[train_targ['results_re'] == 1]) / len(train_targ)\n",
    "print(f'{pct_fail*100:.2f}% reinspections fail in training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = ['violations_orig']\n",
    "train_feat_txt = train_feat[text_col].astype(str)\n",
    "test_feat_txt = test_feat[text_col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          violations_orig\n",
       "236038  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "494289  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "492554  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "97666   18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "290030  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>violations_orig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>236038</th>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n    </tr>\n    <tr>\n      <th>494289</th>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n    </tr>\n    <tr>\n      <th>492554</th>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n    </tr>\n    <tr>\n      <th>97666</th>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n    </tr>\n    <tr>\n      <th>290030</th>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_feat_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab using training set only!!!!\n",
    "for idx, text in train_feat_txt.itertuples():\n",
    "    counter.update(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure what the min frequency should be\n",
    "# Min freq = 1 -> 50768 vocab length\n",
    "# Min freq = 50 -> 2942\n",
    "# Min freq = 100 -> 2211\n",
    "# Min freq = 250 -> 1481\n",
    "# Min freq = 500 -> 1107\n",
    "# Min freq = 1000 -> 806\n",
    "MIN_FREQ = 500\n",
    "vocab = Vocab(counter, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BOW features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - I think we should use absolute rather than relative frequencies for the BOW vectors, as greater number of violations likely provides relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think we can convert numpy arrays to tensors, so I think returning a numpy array here shouldn't be a problem?\n",
    "def collate_into_bow(data, voc):\n",
    "    bow = np.zeros((len(data), len(voc)))\n",
    "    for i, (idx, text) in enumerate(data.itertuples()):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        line_vocab = Vocab(counter)\n",
    "        for token in line_vocab.freqs:\n",
    "            bow[i, voc.stoi[token]] = line_vocab.freqs[token]\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training bow set\n",
    "bow = collate_into_bow(train_feat_txt, vocab)\n",
    "bow_df = pd.DataFrame(bow, columns=vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test bow set using vocab from training set\n",
    "test_bow = collate_into_bow(test_feat_txt, vocab)\n",
    "test_bow_df = pd.DataFrame(test_bow, columns=vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31698, 1108)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "bow_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   <unk>  <pad>     .     ,   and   the    in    of  comments     -  ...  gun  \\\n",
       "0    1.0    0.0  53.0  43.0  48.0  22.0  21.0  29.0      11.0  11.0  ...  0.0   \n",
       "1    1.0    0.0  10.0  10.0   5.0   6.0   5.0   2.0       5.0   5.0  ...  0.0   \n",
       "2    1.0    0.0  27.0  31.0  30.0  32.0  12.0  18.0       7.0   7.0  ...  0.0   \n",
       "3    1.0    0.0  46.0  45.0  44.0  17.0  14.0  20.0      10.0  10.0  ...  0.0   \n",
       "4    1.0    0.0  17.0  22.0  19.0   8.0   4.0  10.0       5.0   5.0  ...  0.0   \n",
       "\n",
       "   disposed  legs  non-toxic  sweep  trays  #7-38-020  toiletroom  holder  \\\n",
       "0       0.0   0.0        0.0    0.0    0.0        0.0         0.0     0.0   \n",
       "1       0.0   0.0        0.0    0.0    0.0        0.0         0.0     0.0   \n",
       "2       0.0   0.0        0.0    0.0    0.0        0.0         0.0     0.0   \n",
       "3       0.0   0.0        0.0    0.0    0.0        0.0         0.0     0.0   \n",
       "4       0.0   0.0        0.0    0.0    0.0        0.0         0.0     0.0   \n",
       "\n",
       "   180f  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 1108 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>&lt;unk&gt;</th>\n      <th>&lt;pad&gt;</th>\n      <th>.</th>\n      <th>,</th>\n      <th>and</th>\n      <th>the</th>\n      <th>in</th>\n      <th>of</th>\n      <th>comments</th>\n      <th>-</th>\n      <th>...</th>\n      <th>gun</th>\n      <th>disposed</th>\n      <th>legs</th>\n      <th>non-toxic</th>\n      <th>sweep</th>\n      <th>trays</th>\n      <th>#7-38-020</th>\n      <th>toiletroom</th>\n      <th>holder</th>\n      <th>180f</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>53.0</td>\n      <td>43.0</td>\n      <td>48.0</td>\n      <td>22.0</td>\n      <td>21.0</td>\n      <td>29.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>27.0</td>\n      <td>31.0</td>\n      <td>30.0</td>\n      <td>32.0</td>\n      <td>12.0</td>\n      <td>18.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>46.0</td>\n      <td>45.0</td>\n      <td>44.0</td>\n      <td>17.0</td>\n      <td>14.0</td>\n      <td>20.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>22.0</td>\n      <td>19.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1108 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Create CBOW features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll need to copy your vector cache to the folder with this notebook!\n",
    "VECTORS_CACHE_DIR = './.vector_cache'\n",
    "DIM_GLOVE = 300\n",
    "\n",
    "glove = GloVe('6B',cache=VECTORS_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_into_cbow(data):\n",
    "    cbow = np.zeros((len(data), DIM_GLOVE))\n",
    "    for i, (idx, text) in enumerate(data.itertuples()):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        tokens = list(Vocab(counter).freqs)\n",
    "        vecs = glove.get_vecs_by_tokens(tokens).numpy()\n",
    "        cbow[i] = np.mean(vecs, axis=0)\n",
    "    return cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training cbow set\n",
    "cbow = collate_into_cbow(train_feat_txt)\n",
    "cbow_df = pd.DataFrame(cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test cbow set\n",
    "test_cbow = collate_into_cbow(train_feat_txt)\n",
    "test_cbow_df = pd.DataFrame(cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer to get ngrams (this was the most intuitive tool I could find...)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=MIN_FREQ, ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_feat_txt['violations_orig'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training ngram set\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "ngram_arr = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31698, 1982)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# There are 1088 2-grams\n",
    "ngram_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "ngram_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test ngram set\n",
    "\n",
    "# I'm pretty sure this is how it's done?\n",
    "corpus_test = test_feat_txt['violations_orig'].to_list()\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "test_ngram_arr = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7925, 1982)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# Should be same dimensionality as training array (1088)\n",
    "test_ngram_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train set into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't shuffle data before splitting\n",
    "train_bow, val_bow, train_targ_spl, val_targ = train_test_split(bow_df, train_targ, test_size=0.2,\n",
    "                                                                shuffle=False)\n",
    "\n",
    "train_cbow, val_cbow = train_test_split(cbow_df, test_size=0.2, shuffle=False)\n",
    "train_2gram, val_2gram = train_test_split(ngram_arr, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversample on target vector\n",
    "train_targ_reset = train_targ_spl.reset_index().drop('index', axis=1)\n",
    "train_targ_fail = train_targ_reset[train_targ_reset['results_re'] == 1]\n",
    "size_diff = train_targ_reset.shape[0] - train_targ_fail.shape[0]\n",
    "train_resample = resample(train_targ_fail, n_samples = size_diff, replace=True)\n",
    "train_targ_all = pd.concat([train_targ_reset, train_resample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-39-b91eb85c8663>:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  train_2gram_resample = train_2gram[[train_targ_all.index]]\n"
     ]
    }
   ],
   "source": [
    "#then resample feature matrices\n",
    "train_bow_resample = train_bow.iloc[train_targ_all.index]\n",
    "train_cbow_resample = train_cbow.iloc[train_targ_all.index]\n",
    "train_2gram_resample = train_2gram[[train_targ_all.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model expects 1d array as target\n",
    "#train_targ_1d = train_targ_spl.iloc[:, 0].ravel()\n",
    "train_targ_1d = train_targ_all.iloc[:, 0].ravel()\n",
    "val_targ_1d = val_targ.iloc[:, 0].ravel()\n",
    "test_targ_1d = test_targ.iloc[:, 0].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline for model will be if we predict 'pass' every time. If model cannot beat these scores, then it is not good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clf_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Accuracy: {accuracy:.2f}\n",
    "    Precision: {precision:.2f}\n",
    "    Recall: {recall:.2f}\n",
    "    F1 score: {f1:.2f}\n",
    "    ROC AUC: {auc:.2f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y_pred array that includes only Passes\n",
    "results = [0] * val_targ.shape[0]\n",
    "d = {'results_re': results}\n",
    "baseline_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Accuracy: 0.91\n    Precision: 0.00\n    Recall: 0.00\n    F1 score: 0.00\n    ROC AUC: 0.50\n    \n"
     ]
    }
   ],
   "source": [
    "print_clf_metrics(val_targ['results_re'], baseline_df['results_re'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Accuracy: 0.78\n    Precision: 0.18\n    Recall: 0.43\n    F1 score: 0.25\n    ROC AUC: 0.62\n    \n"
     ]
    }
   ],
   "source": [
    "# Use multinomial NB b/c features are discrete (counts)\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(train_bow_resample, train_targ_1d)\n",
    "\n",
    "y_pred_bow = nb_bow.predict(val_bow)\n",
    "print_clf_metrics(val_targ_1d, y_pred_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Accuracy: 0.89\n    Precision: 0.02\n    Recall: 0.01\n    F1 score: 0.01\n    ROC AUC: 0.49\n    \n"
     ]
    }
   ],
   "source": [
    "# Use Gaussian NB b/c features now continuous\n",
    "nb_cbow = GaussianNB()\n",
    "nb_cbow.fit(train_cbow_resample, train_targ_1d)\n",
    "\n",
    "y_pred_cbow = nb_cbow.predict(val_cbow)\n",
    "print_clf_metrics(val_targ_1d, y_pred_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-gram model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Accuracy: 0.79\n    Precision: 0.16\n    Recall: 0.34\n    F1 score: 0.22\n    ROC AUC: 0.59\n    \n"
     ]
    }
   ],
   "source": [
    "# Use multinomial NB b/c features are discrete (counts)\n",
    "nb_2gram = MultinomialNB()\n",
    "nb_2gram.fit(train_2gram_resample, train_targ_1d)\n",
    "\n",
    "y_pred_2gram = nb_2gram.predict(val_2gram)\n",
    "print_clf_metrics(val_targ_1d, y_pred_2gram)"
   ]
  },
  {
   "source": [
    "### Logistic Regression model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "BOW model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Accuracy: 0.70\n    Precision: 0.14\n    Recall: 0.51\n    F1 score: 0.22\n    ROC AUC: 0.61\n    \n"
     ]
    }
   ],
   "source": [
    "log_reg_bow = LogisticRegression(max_iter=5000)\n",
    "log_reg_bow.fit(train_bow_resample, train_targ_1d)\n",
    "log_y_pred_bow = log_reg_bow.predict(val_bow)\n",
    "print_clf_metrics(val_targ_1d, log_y_pred_bow)"
   ]
  },
  {
   "source": [
    "CBOW model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Accuracy: 0.66\n    Precision: 0.16\n    Recall: 0.70\n    F1 score: 0.26\n    ROC AUC: 0.68\n    \n"
     ]
    }
   ],
   "source": [
    "log_reg_cbow = LogisticRegression(max_iter=1000)\n",
    "log_reg_cbow.fit(train_cbow_resample, train_targ_1d)\n",
    "log_y_pred_cbow = log_reg_cbow.predict(val_cbow)\n",
    "print_clf_metrics(val_targ_1d, log_y_pred_cbow)"
   ]
  },
  {
   "source": [
    "2-gram model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Accuracy: 0.79\n    Precision: 0.16\n    Recall: 0.34\n    F1 score: 0.22\n    ROC AUC: 0.59\n    \n"
     ]
    }
   ],
   "source": [
    "log_reg_2gram = LogisticRegression(max_iter=5000)\n",
    "log_reg_2gram.fit(train_2gram_resample, train_targ_1d)\n",
    "\n",
    "log_y_pred_2gram = log_reg_2gram.predict(val_2gram)\n",
    "print_clf_metrics(val_targ_1d, y_pred_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0ba539312d09a2ffa8c7e90eb1ed4fb57b0b5103be99f6c8fe3af2b5222ff8312",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "- If we want to keep our prediction binary, we should change all 'Pass w/ Conditions' in the `results_re` field to 'Pass'.\n",
    "- We should also make this field numeric, with Fail as 1 and Pass as 0 (as 'Fail' is the event we are trying to predict). I think we can add both of these to the `data_prep` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questions to discuss:__\n",
    "- __Shuffling during train/test split__: When we do our train/test split, should we sort our data by inspection date first? I know this matters for time series data (where we'd want to avoid leakage of future data into the past), but not sure how much it matters here, where the inspections are generally distinct establishments. Below I did sort the data, and didn't shuffle during the train/test split, but would like your thoughts on whether this matters.\n",
    "- __Word frequency threshold__: In our HW 2, we only included in our vocab words that appeared at least 1000 times in the entire corpus. We'll need to decide what threshold we want to use. I used 1000 below, and also listed the vocab counts at different thresholds.\n",
    "- __Pipeline operations__: What kinds of additional cleaning steps should we perform in our pipeline? Right now, we're just converting words to lower case and splitting them with a tokenizer. Other possible steps include removing stop words and lemmatizing (https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/). I'd recommend we go to Amitabh's office hours to get his thoughts on an appropriate 'good practice' pipeline.\n",
    "- __Relative vs. absolute frequencies for BOW__: In our HW, we implemented BOW with relative frequencies, but I think for our purposes absolute frequencies make more sense, as more words/longer comments can mean more violations. Do you think this makes sense?\n",
    "- __Choice of n for ngrams__: I made an initial choice of 2, which seemed reasonable to me. Would like your thoughts on this, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('initial_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    id_orig                       name  license facility_type  date_orig  \\\n",
       "16   577275                    ROYALTY  1306130    Restaurant 2011-04-18   \n",
       "38  1345428              PRET A MANGER  2138418    Restaurant 2013-08-06   \n",
       "43  1114379              PRET A MANGER  2138418    Restaurant 2012-07-23   \n",
       "65   343293     CHIPOTLE MEXICAN GRILL  1379435    Restaurant 2010-08-17   \n",
       "72  2484973  HILLTOP FAMILY RESTAURANT  2652370    Restaurant 2021-02-19   \n",
       "\n",
       "     inspection_type_orig results_orig  \\\n",
       "16                Canvass         Fail   \n",
       "38                Canvass         Fail   \n",
       "43              Complaint         Fail   \n",
       "65                Canvass         Fail   \n",
       "72  Canvass Re-Inspection         Fail   \n",
       "\n",
       "                                      violations_orig    id_re    date_re  \\\n",
       "16  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...   577343 2011-05-24   \n",
       "38  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  1345448 2013-08-13   \n",
       "43  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  1114384 2012-07-31   \n",
       "65  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...   343310 2010-08-26   \n",
       "72  44. UTENSILS, EQUIPMENT & LINENS: PROPERLY STO...  2485081 2021-02-23   \n",
       "\n",
       "            results_re  time_between  \n",
       "16                Pass           -36  \n",
       "38                Pass            -7  \n",
       "43                Pass            -8  \n",
       "65                Pass            -9  \n",
       "72  Pass w/ Conditions            -4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_orig</th>\n      <th>name</th>\n      <th>license</th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>id_re</th>\n      <th>date_re</th>\n      <th>results_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>577275</td>\n      <td>ROYALTY</td>\n      <td>1306130</td>\n      <td>Restaurant</td>\n      <td>2011-04-18</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>577343</td>\n      <td>2011-05-24</td>\n      <td>Pass</td>\n      <td>-36</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1345428</td>\n      <td>PRET A MANGER</td>\n      <td>2138418</td>\n      <td>Restaurant</td>\n      <td>2013-08-06</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>1345448</td>\n      <td>2013-08-13</td>\n      <td>Pass</td>\n      <td>-7</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1114379</td>\n      <td>PRET A MANGER</td>\n      <td>2138418</td>\n      <td>Restaurant</td>\n      <td>2012-07-23</td>\n      <td>Complaint</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>1114384</td>\n      <td>2012-07-31</td>\n      <td>Pass</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>343293</td>\n      <td>CHIPOTLE MEXICAN GRILL</td>\n      <td>1379435</td>\n      <td>Restaurant</td>\n      <td>2010-08-17</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>343310</td>\n      <td>2010-08-26</td>\n      <td>Pass</td>\n      <td>-9</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>2484973</td>\n      <td>HILLTOP FAMILY RESTAURANT</td>\n      <td>2652370</td>\n      <td>Restaurant</td>\n      <td>2021-02-19</td>\n      <td>Canvass Re-Inspection</td>\n      <td>Fail</td>\n      <td>44. UTENSILS, EQUIPMENT &amp; LINENS: PROPERLY STO...</td>\n      <td>2485081</td>\n      <td>2021-02-23</td>\n      <td>Pass w/ Conditions</td>\n      <td>-4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Pass w/ Conditions' to 'Pass', and change target to 0/1 numeric\n",
    "results_dict = {'Pass': 0, 'Fail': 1}\n",
    "df['results_re'] = df['results_re'].str.replace('Pass w/ Conditions', 'Pass')\n",
    "df['results_re'] = df['results_re'].apply(lambda x: results_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into feature & target, and then into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by inspection date\n",
    "# Training set will include initial 80% of inspections\n",
    "sorted_df = df.sort_values(by=['date_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       id_orig                       name  license  facility_type  date_orig  \\\n",
       "217726  104236                 TEMPO CAFE    80916     Restaurant 2010-01-04   \n",
       "494307   67738     MICHAEL'S ON MAIN CAFE  2008948     Restaurant 2010-01-04   \n",
       "452398   67736  MONTICELLO FOOD MART, INC  2013259  Grocery Store 2010-01-05   \n",
       "281119   67741                      CITGO  2013296  Grocery Store 2010-01-05   \n",
       "460847   67744    GOLDEN CROWN RESTAURANT  2013539     Restaurant 2010-01-05   \n",
       "\n",
       "       inspection_type_orig results_orig  \\\n",
       "217726              Canvass         Fail   \n",
       "494307              License         Fail   \n",
       "452398              License         Fail   \n",
       "281119              License         Fail   \n",
       "460847              License         Fail   \n",
       "\n",
       "                                          violations_orig   id_re    date_re  \\\n",
       "217726  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  104243 2010-01-12   \n",
       "494307  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  124279 2010-01-19   \n",
       "452398  21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE...   54219 2010-01-08   \n",
       "281119  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...  176270 2010-02-17   \n",
       "460847  32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL...   48215 2010-01-11   \n",
       "\n",
       "        results_re  time_between  \n",
       "217726           0            -8  \n",
       "494307           0           -15  \n",
       "452398           0            -3  \n",
       "281119           0           -43  \n",
       "460847           1            -6  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_orig</th>\n      <th>name</th>\n      <th>license</th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>id_re</th>\n      <th>date_re</th>\n      <th>results_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>217726</th>\n      <td>104236</td>\n      <td>TEMPO CAFE</td>\n      <td>80916</td>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>104243</td>\n      <td>2010-01-12</td>\n      <td>0</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>494307</th>\n      <td>67738</td>\n      <td>MICHAEL'S ON MAIN CAFE</td>\n      <td>2008948</td>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>124279</td>\n      <td>2010-01-19</td>\n      <td>0</td>\n      <td>-15</td>\n    </tr>\n    <tr>\n      <th>452398</th>\n      <td>67736</td>\n      <td>MONTICELLO FOOD MART, INC</td>\n      <td>2013259</td>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE...</td>\n      <td>54219</td>\n      <td>2010-01-08</td>\n      <td>0</td>\n      <td>-3</td>\n    </tr>\n    <tr>\n      <th>281119</th>\n      <td>67741</td>\n      <td>CITGO</td>\n      <td>2013296</td>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n      <td>176270</td>\n      <td>2010-02-17</td>\n      <td>0</td>\n      <td>-43</td>\n    </tr>\n    <tr>\n      <th>460847</th>\n      <td>67744</td>\n      <td>GOLDEN CROWN RESTAURANT</td>\n      <td>2013539</td>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL...</td>\n      <td>48215</td>\n      <td>2010-01-11</td>\n      <td>1</td>\n      <td>-6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['results_re']\n",
    "target = sorted_df[target_col]\n",
    "\n",
    "cols_to_exclude = ['name', 'id_orig', 'id_re', 'license']\n",
    "feature_cols = [col for col in sorted_df.columns if (col not in cols_to_exclude and col not in target_col)]\n",
    "features = sorted_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        results_re\n",
       "217726           0\n",
       "494307           0\n",
       "452398           0\n",
       "281119           0\n",
       "460847           1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>results_re</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>217726</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>494307</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>452398</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>281119</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>460847</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        facility_type  date_orig inspection_type_orig results_orig  \\\n",
       "217726     Restaurant 2010-01-04              Canvass         Fail   \n",
       "494307     Restaurant 2010-01-04              License         Fail   \n",
       "452398  Grocery Store 2010-01-05              License         Fail   \n",
       "281119  Grocery Store 2010-01-05              License         Fail   \n",
       "460847     Restaurant 2010-01-05              License         Fail   \n",
       "\n",
       "                                          violations_orig    date_re  \\\n",
       "217726  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "494307  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-19   \n",
       "452398  21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE... 2010-01-08   \n",
       "281119  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -... 2010-02-17   \n",
       "460847  32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL... 2010-01-11   \n",
       "\n",
       "        time_between  \n",
       "217726            -8  \n",
       "494307           -15  \n",
       "452398            -3  \n",
       "281119           -43  \n",
       "460847            -6  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>date_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>217726</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-12</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>494307</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-19</td>\n      <td>-15</td>\n    </tr>\n    <tr>\n      <th>452398</th>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE...</td>\n      <td>2010-01-08</td>\n      <td>-3</td>\n    </tr>\n    <tr>\n      <th>281119</th>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n      <td>2010-02-17</td>\n      <td>-43</td>\n    </tr>\n    <tr>\n      <th>460847</th>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL...</td>\n      <td>2010-01-11</td>\n      <td>-6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't shuffle data before splitting\n",
    "train_feat, test_feat, train_targ, test_targ = train_test_split(features, target, test_size=0.2,\n",
    "                                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        facility_type  date_orig inspection_type_orig results_orig  \\\n",
       "217726     Restaurant 2010-01-04              Canvass         Fail   \n",
       "494307     Restaurant 2010-01-04              License         Fail   \n",
       "452398  Grocery Store 2010-01-05              License         Fail   \n",
       "281119  Grocery Store 2010-01-05              License         Fail   \n",
       "460847     Restaurant 2010-01-05              License         Fail   \n",
       "\n",
       "                                          violations_orig    date_re  \\\n",
       "217726  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "494307  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-19   \n",
       "452398  21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE... 2010-01-08   \n",
       "281119  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -... 2010-02-17   \n",
       "460847  32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL... 2010-01-11   \n",
       "\n",
       "        time_between  \n",
       "217726            -8  \n",
       "494307           -15  \n",
       "452398            -3  \n",
       "281119           -43  \n",
       "460847            -6  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facility_type</th>\n      <th>date_orig</th>\n      <th>inspection_type_orig</th>\n      <th>results_orig</th>\n      <th>violations_orig</th>\n      <th>date_re</th>\n      <th>time_between</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>217726</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>Canvass</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-12</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>494307</th>\n      <td>Restaurant</td>\n      <td>2010-01-04</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n      <td>2010-01-19</td>\n      <td>-15</td>\n    </tr>\n    <tr>\n      <th>452398</th>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE...</td>\n      <td>2010-01-08</td>\n      <td>-3</td>\n    </tr>\n    <tr>\n      <th>281119</th>\n      <td>Grocery Store</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n      <td>2010-02-17</td>\n      <td>-43</td>\n    </tr>\n    <tr>\n      <th>460847</th>\n      <td>Restaurant</td>\n      <td>2010-01-05</td>\n      <td>License</td>\n      <td>Fail</td>\n      <td>32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL...</td>\n      <td>2010-01-11</td>\n      <td>-6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8.80% reinspections fail in training set\n"
     ]
    }
   ],
   "source": [
    "pct_fail = len(train_targ[train_targ['results_re'] == 1]) / len(train_targ)\n",
    "print(f'{pct_fail*100:.2f}% reinspections fail in training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = ['violations_orig']\n",
    "train_feat_txt = train_feat[text_col].astype(str)\n",
    "test_feat_txt = test_feat[text_col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          violations_orig\n",
       "217726  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "494307  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "452398  21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE...\n",
       "281119  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...\n",
       "460847  32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>violations_orig</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>217726</th>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n    </tr>\n    <tr>\n      <th>494307</th>\n      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n    </tr>\n    <tr>\n      <th>452398</th>\n      <td>21. * CERTIFIED FOOD MANAGER ON SITE WHEN POTE...</td>\n    </tr>\n    <tr>\n      <th>281119</th>\n      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n    </tr>\n    <tr>\n      <th>460847</th>\n      <td>32. FOOD AND NON-FOOD CONTACT SURFACES PROPERL...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_feat_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab using training set only!!!!\n",
    "for idx, text in train_feat_txt.itertuples():\n",
    "    counter.update(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure what the min frequency should be\n",
    "# Min freq = 1 -> 50768 vocab length\n",
    "# Min freq = 50 -> 2942\n",
    "# Min freq = 100 -> 2211\n",
    "# Min freq = 250 -> 1481\n",
    "# Min freq = 500 -> 1107\n",
    "# Min freq = 1000 -> 806\n",
    "MIN_FREQ = 500\n",
    "vocab = Vocab(counter, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1086"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BOW features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - I think we should use absolute rather than relative frequencies for the BOW vectors, as greater number of violations likely provides relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_into_bow(data, voc):\n",
    "    bow = np.zeros((len(data), len(voc)))\n",
    "    token_counts = np.zeros((len(data), 1))\n",
    "    for i, (idx, text) in enumerate(data.itertuples()):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        line_vocab = Vocab(counter)\n",
    "        tot_freqs = sum(line_vocab.freqs.values())\n",
    "        token_counts[i] = tot_freqs\n",
    "        for token in line_vocab.freqs:\n",
    "            bow[i, voc.stoi[token]] = line_vocab.freqs[token] / tot_freqs  # Using relative frequencies\n",
    "    return token_counts, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training bow set\n",
    "token_counts, bow = collate_into_bow(train_feat_txt, vocab)\n",
    "bow_concat = np.concatenate((bow, token_counts), axis=1)\n",
    "bow_df = pd.DataFrame(bow_concat, columns=vocab.itos + ['token_counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test bow set using vocab from training set\n",
    "test_token_counts, test_bow = collate_into_bow(test_feat_txt, vocab)\n",
    "test_bow_concat = np.concatenate((test_bow, test_token_counts), axis=1)\n",
    "test_bow_df = pd.DataFrame(test_bow_concat, columns=vocab.itos + ['token_counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Create CBOW features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll need to copy your vector cache to the folder with this notebook!\n",
    "VECTORS_CACHE_DIR = './.vector_cache'\n",
    "DIM_GLOVE = 300\n",
    "\n",
    "glove = GloVe('6B',cache=VECTORS_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_into_cbow(data):\n",
    "    cbow = np.zeros((len(data), DIM_GLOVE))\n",
    "    for i, (idx, text) in enumerate(data.itertuples()):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        tokens = list(Vocab(counter).freqs)\n",
    "        vecs = glove.get_vecs_by_tokens(tokens).numpy()\n",
    "        cbow[i] = np.mean(vecs, axis=0)\n",
    "    return cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training cbow set\n",
    "cbow = collate_into_cbow(train_feat_txt)\n",
    "cbow_df = pd.DataFrame(cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test cbow set\n",
    "test_cbow = collate_into_cbow(train_feat_txt)\n",
    "test_cbow_df = pd.DataFrame(cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer to get ngrams (this was the most intuitive tool I could find...)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_rows_by_row_sum(arr):\n",
    "    return np.nan_to_num(\n",
    "            np.divide(arr, arr.sum(axis=1)[:, None]),\n",
    "            nan=0  # Small number of ngram rows are all zeroes; don't divide row by 0 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=MIN_FREQ, ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_feat_txt['violations_orig'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-27-17bb06bbd3b0>:3: RuntimeWarning: invalid value encountered in true_divide\n  np.divide(arr, arr.sum(axis=1)[:, None]),\n"
     ]
    }
   ],
   "source": [
    "# Create training ngram set\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "ngram_arr = X.toarray()\n",
    "ngram_arr = divide_rows_by_row_sum(ngram_arr)\n",
    "ngram_arr = np.concatenate((ngram_arr, token_counts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-27-17bb06bbd3b0>:3: RuntimeWarning: invalid value encountered in true_divide\n  np.divide(arr, arr.sum(axis=1)[:, None]),\n"
     ]
    }
   ],
   "source": [
    "# Create test ngram set\n",
    "\n",
    "# I'm pretty sure this is how it's done?\n",
    "corpus_test = test_feat_txt['violations_orig'].to_list()\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "test_ngram_arr = X_test.toarray()\n",
    "test_ngram_arr = divide_rows_by_row_sum(test_ngram_arr)\n",
    "test_ngram_arr = np.concatenate((test_ngram_arr, test_token_counts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7442, 1907)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Should be same dimensionality as training array (1088)\n",
    "test_ngram_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train set into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't shuffle data before splitting\n",
    "train_bow, val_bow, train_targ_spl, val_targ = train_test_split(bow_df, train_targ, test_size=0.2,\n",
    "                                                                shuffle=False)\n",
    "\n",
    "train_cbow, val_cbow = train_test_split(cbow_df, test_size=0.2, shuffle=False)\n",
    "train_2gram, val_2gram = train_test_split(ngram_arr, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversample on target vector\n",
    "train_targ_reset = train_targ_spl.reset_index().drop('index', axis=1)\n",
    "train_targ_fail = train_targ_reset[train_targ_reset['results_re'] == 1]\n",
    "size_diff = train_targ_reset.shape[0] - train_targ_fail.shape[0]\n",
    "train_resample = resample(train_targ_fail, n_samples = size_diff, replace=True)\n",
    "train_targ_all = pd.concat([train_targ_reset, train_resample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-35-b91eb85c8663>:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  train_2gram_resample = train_2gram[[train_targ_all.index]]\n"
     ]
    }
   ],
   "source": [
    "#then resample feature matrices\n",
    "train_bow_resample = train_bow.iloc[train_targ_all.index]\n",
    "train_cbow_resample = train_cbow.iloc[train_targ_all.index]\n",
    "train_2gram_resample = train_2gram[[train_targ_all.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model expects 1d array as target\n",
    "#train_targ_1d = train_targ_spl.iloc[:, 0].ravel()\n",
    "train_targ_1d = train_targ_all.iloc[:, 0].ravel()\n",
    "val_targ_1d = val_targ.iloc[:, 0].ravel()\n",
    "test_targ_1d = test_targ.iloc[:, 0].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline for model will be if we predict 'pass' every time. If model cannot beat these scores, then it is not good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clf_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Accuracy: {accuracy:.2f}\n",
    "    Precision: {precision:.2f}\n",
    "    Recall: {recall:.2f}\n",
    "    F1 score: {f1:.2f}\n",
    "    ROC AUC: {auc:.2f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y_pred array that includes only Passes\n",
    "results = [0] * val_targ.shape[0]\n",
    "d = {'results_re': results}\n",
    "baseline_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.91\n",
      "    Precision: 0.00\n",
      "    Recall: 0.00\n",
      "    F1 score: 0.00\n",
      "    ROC AUC: 0.50\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print_clf_metrics(val_targ['results_re'], baseline_df['results_re'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.47\n",
      "    Precision: 0.12\n",
      "    Recall: 0.78\n",
      "    F1 score: 0.22\n",
      "    ROC AUC: 0.61\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Use multinomial NB b/c features are discrete (counts)\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(train_bow_resample, train_targ_1d)\n",
    "\n",
    "y_pred_bow = nb_bow.predict(val_bow)\n",
    "print_clf_metrics(val_targ_1d, y_pred_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.89\n",
      "    Precision: 0.03\n",
      "    Recall: 0.01\n",
      "    F1 score: 0.01\n",
      "    ROC AUC: 0.49\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Use Gaussian NB b/c features now continuous\n",
    "nb_cbow = GaussianNB()\n",
    "nb_cbow.fit(train_cbow_resample, train_targ_1d)\n",
    "\n",
    "y_pred_cbow = nb_cbow.predict(val_cbow)\n",
    "print_clf_metrics(val_targ_1d, y_pred_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-gram model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.53\n",
      "    Precision: 0.14\n",
      "    Recall: 0.76\n",
      "    F1 score: 0.23\n",
      "    ROC AUC: 0.63\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Use multinomial NB b/c features are discrete (counts)\n",
    "nb_2gram = MultinomialNB()\n",
    "nb_2gram.fit(train_2gram_resample, train_targ_1d)\n",
    "\n",
    "y_pred_2gram = nb_2gram.predict(val_2gram)\n",
    "print_clf_metrics(val_targ_1d, y_pred_2gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.61\n",
      "    Precision: 0.14\n",
      "    Recall: 0.64\n",
      "    F1 score: 0.23\n",
      "    ROC AUC: 0.62\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "log_reg_bow = LogisticRegression(max_iter=5000)\n",
    "log_reg_bow.fit(train_bow_resample, train_targ_1d)\n",
    "log_y_pred_bow = log_reg_bow.predict(val_bow)\n",
    "print_clf_metrics(val_targ_1d, log_y_pred_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.63\n",
      "    Precision: 0.16\n",
      "    Recall: 0.72\n",
      "    F1 score: 0.26\n",
      "    ROC AUC: 0.67\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "log_reg_cbow = LogisticRegression(max_iter=1000)\n",
    "log_reg_cbow.fit(train_cbow_resample, train_targ_1d)\n",
    "log_y_pred_cbow = log_reg_cbow.predict(val_cbow)\n",
    "print_clf_metrics(val_targ_1d, log_y_pred_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-gram model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy: 0.61\n",
      "    Precision: 0.15\n",
      "    Recall: 0.66\n",
      "    F1 score: 0.24\n",
      "    ROC AUC: 0.63\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "log_reg_2gram = LogisticRegression(max_iter=5000)\n",
    "log_reg_2gram.fit(train_2gram_resample, train_targ_1d)\n",
    "\n",
    "log_y_pred_2gram = log_reg_2gram.predict(val_2gram)\n",
    "print_clf_metrics(val_targ_1d, log_y_pred_2gram)"
   ]
  },
  {
   "source": [
    "### Grid Search on Logistic Regression and SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_log = {'C': [0.3, 0.5, 0.7]}\n",
    "#scikit learn uses L2 penalty (ridge) by default, with C=1\n",
    "\n",
    "scoring = {'Accuracy': 'accuracy', 'Precision': 'precision', 'Recall': 'recall'}\n",
    "\n",
    "def grid_search_log(train_x, train_y, max_iter=5000):\n",
    "    grid_log = GridSearchCV(LogisticRegression(max_iter=max_iter, random_state=0), param_grid=parameters_log, scoring=scoring,\n",
    "                            cv=5, refit='Precision')\n",
    "    grid_log.fit(train_x, train_y)\n",
    "    logs_all = pd.DataFrame.from_dict(grid_log.cv_results_)\n",
    "    return(logs_all.loc[:, ['param_C', 'mean_test_Accuracy', 'mean_test_Precision', 'mean_test_Recall', 'rank_test_Precision']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  param_C  mean_test_Accuracy  mean_test_Precision  mean_test_Recall  \\\n",
       "0     0.3            0.591527             0.613999          0.625384   \n",
       "1     0.5            0.587861             0.610199          0.631809   \n",
       "2     0.7            0.584546             0.606823          0.635421   \n",
       "\n",
       "   rank_test_Precision  \n",
       "0                    1  \n",
       "1                    2  \n",
       "2                    3  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_C</th>\n      <th>mean_test_Accuracy</th>\n      <th>mean_test_Precision</th>\n      <th>mean_test_Recall</th>\n      <th>rank_test_Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.3</td>\n      <td>0.591527</td>\n      <td>0.613999</td>\n      <td>0.625384</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.587861</td>\n      <td>0.610199</td>\n      <td>0.631809</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7</td>\n      <td>0.584546</td>\n      <td>0.606823</td>\n      <td>0.635421</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "grid_search_log(train_bow_resample, train_targ_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  param_C  mean_test_Accuracy  mean_test_Precision  mean_test_Recall  \\\n",
       "0     0.3            0.627966             0.623519          0.757549   \n",
       "1     0.5            0.630469             0.625990          0.756037   \n",
       "2     0.7            0.631435             0.627015          0.755072   \n",
       "\n",
       "   rank_test_Precision  \n",
       "0                    3  \n",
       "1                    2  \n",
       "2                    1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_C</th>\n      <th>mean_test_Accuracy</th>\n      <th>mean_test_Precision</th>\n      <th>mean_test_Recall</th>\n      <th>rank_test_Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.3</td>\n      <td>0.627966</td>\n      <td>0.623519</td>\n      <td>0.757549</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.630469</td>\n      <td>0.625990</td>\n      <td>0.756037</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7</td>\n      <td>0.631435</td>\n      <td>0.627015</td>\n      <td>0.755072</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "grid_search_log(train_cbow_resample, train_targ_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  param_C  mean_test_Accuracy  mean_test_Precision  mean_test_Recall  \\\n",
       "0     0.3            0.602020             0.622411          0.618034   \n",
       "1     0.5            0.599868             0.619125          0.619672   \n",
       "2     0.7            0.603271             0.622957          0.621184   \n",
       "\n",
       "   rank_test_Precision  \n",
       "0                    2  \n",
       "1                    3  \n",
       "2                    1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_C</th>\n      <th>mean_test_Accuracy</th>\n      <th>mean_test_Precision</th>\n      <th>mean_test_Recall</th>\n      <th>rank_test_Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.3</td>\n      <td>0.602020</td>\n      <td>0.622411</td>\n      <td>0.618034</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.599868</td>\n      <td>0.619125</td>\n      <td>0.619672</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7</td>\n      <td>0.603271</td>\n      <td>0.622957</td>\n      <td>0.621184</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "grid_search_log(train_2gram_resample, train_targ_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {'C': [0.1, 1, 10]}\n",
    "\n",
    "scoring = {'Accuracy': 'accuracy', 'Precision': 'precision', 'Recall': 'recall'}\n",
    "\n",
    "def grid_search_svm(train_x, train_y, max_iter=10000):\n",
    "    grid_svm = GridSearchCV(LinearSVC(max_iter=max_iter, random_state=0), param_grid=parameters_log, scoring=scoring,\n",
    "                            cv=3, refit='Precision')\n",
    "    grid_svm.fit(train_x, train_y)\n",
    "    svm_all = pd.DataFrame.from_dict(grid_svm.cv_results_)\n",
    "    return(svm_all.loc[:, ['param_C', 'mean_test_Accuracy', 'mean_test_Precision', 'mean_test_Recall', 'rank_test_Precision']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  param_C  mean_test_Accuracy  mean_test_Precision  mean_test_Recall  \\\n",
       "0     0.3            0.525431             0.558997          0.574384   \n",
       "1     0.5            0.528438             0.571346          0.514590   \n",
       "2     0.7            0.504774             0.613656          0.410542   \n",
       "\n",
       "   rank_test_Precision  \n",
       "0                    3  \n",
       "1                    2  \n",
       "2                    1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_C</th>\n      <th>mean_test_Accuracy</th>\n      <th>mean_test_Precision</th>\n      <th>mean_test_Recall</th>\n      <th>rank_test_Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.3</td>\n      <td>0.525431</td>\n      <td>0.558997</td>\n      <td>0.574384</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.528438</td>\n      <td>0.571346</td>\n      <td>0.514590</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7</td>\n      <td>0.504774</td>\n      <td>0.613656</td>\n      <td>0.410542</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "grid_search_svm(train_bow_resample, train_targ_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  param_C  mean_test_Accuracy  mean_test_Precision  mean_test_Recall  \\\n",
       "0     0.3            0.578158             0.579390          0.752005   \n",
       "1     0.5            0.576358             0.578143          0.749234   \n",
       "2     0.7            0.577719             0.579200          0.750451   \n",
       "\n",
       "   rank_test_Precision  \n",
       "0                    1  \n",
       "1                    3  \n",
       "2                    2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_C</th>\n      <th>mean_test_Accuracy</th>\n      <th>mean_test_Precision</th>\n      <th>mean_test_Recall</th>\n      <th>rank_test_Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.3</td>\n      <td>0.578158</td>\n      <td>0.579390</td>\n      <td>0.752005</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.576358</td>\n      <td>0.578143</td>\n      <td>0.749234</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7</td>\n      <td>0.577719</td>\n      <td>0.579200</td>\n      <td>0.750451</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "grid_search_svm(train_cbow_resample, train_targ_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\alipe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  param_C  mean_test_Accuracy  mean_test_Precision  mean_test_Recall  \\\n",
       "0     0.3            0.528438             0.526754          0.963294   \n",
       "1     0.5            0.509714             0.567246          0.641174   \n",
       "2     0.7            0.510109             0.582666          0.632229   \n",
       "\n",
       "   rank_test_Precision  \n",
       "0                    3  \n",
       "1                    2  \n",
       "2                    1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_C</th>\n      <th>mean_test_Accuracy</th>\n      <th>mean_test_Precision</th>\n      <th>mean_test_Recall</th>\n      <th>rank_test_Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.3</td>\n      <td>0.528438</td>\n      <td>0.526754</td>\n      <td>0.963294</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.509714</td>\n      <td>0.567246</td>\n      <td>0.641174</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7</td>\n      <td>0.510109</td>\n      <td>0.582666</td>\n      <td>0.632229</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "grid_search_svm(train_2gram_resample, train_targ_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0ba539312d09a2ffa8c7e90eb1ed4fb57b0b5103be99f6c8fe3af2b5222ff8312",
   "display_name": "Python 3.8.5 64-bit ('alipe': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
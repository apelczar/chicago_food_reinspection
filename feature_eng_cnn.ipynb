{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(\"Using cuda.\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(\"Using cpu.\")\n",
    "    \n",
    "random.seed(30255)\n",
    "np.random.seed(30255)\n",
    "torch.manual_seed(30255)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(30255)\n",
    "    \n",
    "COLAB = False\n",
    "#COLAB = True\n",
    "if COLAB:\n",
    "    from google.colab import drive \n",
    "    drive.mount('/content/gdrive')\n",
    "    PATH = \"gdrive/My Drive/advanced_ml/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    df = pd.read_pickle(PATH + 'initial_clean.pkl')\n",
    "else:\n",
    "    df = pd.read_pickle('initial_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'df currently has {df.shape[0]} rows')\n",
    "\n",
    "# Remove rows with no comments\n",
    "df = df[df['violations_orig'].notna()]\n",
    "print(f'df now has {df.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Pass w/ Conditions' to 'Pass' and change target to 0/1 numeric\n",
    "results_dict = {'Pass': 0, 'Fail': 1}\n",
    "df['results_re'] = df['results_re'].str.replace('Pass w/ Conditions', 'Pass')\n",
    "df['results_re'] = df['results_re'].apply(lambda x: results_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into feature & target, and then into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by inspection date\n",
    "# Training set will include initial 80% of inspections\n",
    "sorted_df = df.sort_values(by=['date_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['results_re']\n",
    "target = sorted_df[target_col]\n",
    "\n",
    "cols_to_exclude = ['name', 'id_orig', 'id_re', 'license']\n",
    "feature_cols = [col for col in sorted_df.columns if (col not in cols_to_exclude and col not in target_col)]\n",
    "features = sorted_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't shuffle data before splitting\n",
    "train_feat, test_feat, train_targ, test_targ = train_test_split(features, target, test_size=0.2,\n",
    "                                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_fail = len(train_targ[train_targ['results_re'] == 1]) / len(train_targ)\n",
    "print(f'{pct_fail*100:.2f}% reinspections fail in training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = ['violations_orig']\n",
    "train_feat_txt = train_feat[text_col].astype(str)\n",
    "test_feat_txt = test_feat[text_col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab using training set only!!!!\n",
    "for idx, text in train_feat_txt.itertuples():\n",
    "    counter.update(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure what the min frequency should be\n",
    "# Min freq = 1 -> 50768 vocab length\n",
    "# Min freq = 50 -> 2942\n",
    "# Min freq = 100 -> 2211\n",
    "# Min freq = 250 -> 1481\n",
    "# Min freq = 500 -> 1107\n",
    "# Min freq = 1000 -> 806\n",
    "MIN_FREQ = 500\n",
    "vocab = Vocab(counter, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_into_bow(data, voc=vocab):\n",
    "    bow = torch.zeros((len(data), len(voc) + 1))\n",
    "    labels = torch.zeros((len(data), 1))\n",
    "    for i, (label, text) in enumerate(data):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        line_vocab = Vocab(counter)\n",
    "        tot_freqs = sum(line_vocab.freqs.values())\n",
    "        labels[i] = label\n",
    "        for token in line_vocab.freqs:\n",
    "            bow[i, voc.stoi[token]] = line_vocab.freqs[token] / tot_freqs  # Using relative frequencies\n",
    "            bow[i, -1] = tot_freqs\n",
    "    \n",
    "    return (labels, bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Create CBOW features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORS_CACHE_DIR = './.vector_cache'\n",
    "DIM_GLOVE = 300\n",
    "\n",
    "glove = GloVe('6B',cache=VECTORS_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_into_cbow(data):\n",
    "    cbow = torch.zeros((len(data), DIM_GLOVE))\n",
    "    labels = torch.zeros((len(data), 1))\n",
    "    for i, (label, text) in enumerate(data):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        tokens = list(Vocab(counter).freqs)\n",
    "        vecs = glove.get_vecs_by_tokens(tokens)\n",
    "        cbow[i] = torch.mean(vecs, axis=0)\n",
    "        labels[i] = label\n",
    "    return (labels, cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer to get ngrams (this was the most intuitive tool I could find...)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_rows_by_row_sum(arr):\n",
    "    return np.nan_to_num(\n",
    "            np.divide(arr, arr.sum(axis=1)[:, None]),\n",
    "            nan=0  # Small number of ngram rows are all zeroes; don't divide row by 0 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=MIN_FREQ, ngram_range=(2,2))\n",
    "corpus = train_feat_txt['violations_orig'].to_list()\n",
    "vocab_ngrams = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm not sure how to get this to include document length, since\n",
    "#I had to alter the BOW collate function so it would work\n",
    "#with the dataloader\n",
    "\n",
    "def collate_into_ngrams(data, voc=vocab_ngrams):\n",
    "    ngrams = torch.zeros((len(data), voc.shape[1]))\n",
    "    labels = torch.zeros((len(data), 1))\n",
    "    for i, (label, text) in enumerate(data):\n",
    "        X_batch = vectorizer.transform([text])\n",
    "        ngram_arr = X_batch.toarray()\n",
    "        ngram_arr = divide_rows_by_row_sum(ngram_arr)\n",
    "        ngrams[i, :] = torch.tensor(ngram_arr)\n",
    "        labels[i] = label\n",
    "    \n",
    "    return (labels, ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train set into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_feat_txt, train_targ,\n",
    "                                                    test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversample on target vector\n",
    "train_targ_reset = train_y.reset_index().drop('index', axis=1)\n",
    "train_targ_fail = train_targ_reset[train_targ_reset['results_re'] == 1]\n",
    "size_diff = train_targ_reset.shape[0] - train_targ_fail.shape[0]\n",
    "train_resample = resample(train_targ_fail, n_samples = size_diff, replace=True)\n",
    "train_targ_all = pd.concat([train_targ_reset, train_resample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class InspectionsDataset(Dataset):\n",
    "    def __init__(self, features_df, target_df):\n",
    "\n",
    "        self.features_text = features_df['violations_orig']\n",
    "        self.labels = target_df['results_re']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features_text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.features_text.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        return (label, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then resample features\n",
    "train_x_reset = train_x.reset_index().drop('index', axis=1)\n",
    "train_x_resample = train_x_reset.iloc[train_targ_all.index]\n",
    "\n",
    "#and convert to dataset object\n",
    "inspections_train = InspectionsDataset(train_x_resample, train_targ_all)\n",
    "inspections_val = InspectionsDataset(val_x, val_y)\n",
    "inspections_test = InspectionsDataset(test_feat_txt, test_targ)\n",
    "\n",
    "#these can all now be fed into DataLoaders with the proper collate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text and label in 1 file\n",
    "df_train = pd.concat([train_x_resample, train_targ_all], axis=1)\n",
    "df_valid = pd.concat([val_x, val_y], axis=1)\n",
    "df_test = pd.concat([test_feat_txt, test_targ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data prep informed by: https://www.kaggle.com/swarnabha/pytorch-text-classification-torchtext-lstm<br>\n",
    "- Model building informed by: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field, LabelField, TabularDataset, BucketIterator, Example, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Field objects to process the text data\n",
    "# they will include info for how to convert the text to tensors\n",
    "TEXT = Field(tokenize='basic_english', lower=True, batch_first=True)\n",
    "LABEL = LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://gist.github.com/lextoumbourou/8f90313cbc3598ffbabeeaa1741a11c8\n",
    "# to use DataFrame as a Data source\n",
    "class DataFrameDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.results_re\n",
    "            text = row.violations_orig\n",
    "            examples.append(Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.violations_orig)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        data_field = fields\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
    "        if val_df is not None:\n",
    "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset objects using the train and validation dataframes\n",
    "fields = [('violations_orig', TEXT), ('results_re', LABEL)]\n",
    "train_ds, val_ds, test_ds = DataFrameDataset.splits(fields, train_df=df_train,\n",
    "                                                    val_df=df_valid, test_df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocab using original training set\n",
    "\n",
    "# ***NOTE*** - this builds the vocab using the train dataset that was split\n",
    "# from the validation dataset (couldn't get it to work otherwise)\n",
    "TEXT.build_vocab(train_ds, vectors = 'glove.6B.300d', min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure new vocab is the same as original vocab\n",
    "print('Length of new vocab is...', len(TEXT.vocab.itos))\n",
    "print('Length of original vocab is...', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build iterators\n",
    "BATCH_SIZE=64\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_ds, val_ds, test_ds),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.violations_orig),\n",
    "#     sort_within_batch = True,\n",
    "    device = DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Build, Training, & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained embeddings\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero out the initial weights of the unknown and padding tokens\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 100\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.violations_orig).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.results_re)\n",
    "        acc = binary_accuracy(predictions, batch.results_re)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            print(f'At iteration {i} the training accuracy is {acc:.3f}.')\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.violations_orig).squeeze(1)\n",
    "            loss = criterion(predictions, batch.results_re)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.results_re)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics on validation set\n",
    "from ignite.metrics import Precision\n",
    "from ignite.metrics import Recall\n",
    "from ignite.metrics import Accuracy\n",
    "\n",
    "model.eval()\n",
    "precision = Precision()\n",
    "recall = Recall()\n",
    "accuracy = Accuracy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in valid_iterator:\n",
    "        preds = model(batch.violations_orig).squeeze(1)\n",
    "        rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "        precision.update((rounded_preds, batch.results_re))\n",
    "        recall.update((rounded_preds, batch.results_re))\n",
    "        accuracy.update((rounded_preds, batch.results_re))\n",
    "        \n",
    "print('Precision: ', precision.compute())\n",
    "print('Recall: ', recall.compute())\n",
    "print('Accuracy: ', accuracy.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloaders\n",
    "train_dataloader = DataLoader(inspections_train, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                                collate_fn=collate_into_cbow)\n",
    "val_dataloader = DataLoader(inspections_val, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_cbow)\n",
    "test_dataloader = DataLoader(inspections_test, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloaders\n",
    "train_dataloader = DataLoader(inspections_train, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                                collate_fn=collate_into_ngrams)\n",
    "val_dataloader = DataLoader(inspections_val, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_ngrams)\n",
    "test_dataloader = DataLoader(inspections_test, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

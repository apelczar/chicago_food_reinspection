{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /Users/michaelfeldman/opt/anaconda3/include/python3.7m/UNKNOWN\n",
      "sysconfig: /Users/michaelfeldman/opt/anaconda3/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: torchtext in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: torch==1.8.0 in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from torchtext) (1.8.0)\n",
      "Requirement already satisfied: tqdm in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from torchtext) (4.60.0)\n",
      "Requirement already satisfied: requests in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from torchtext) (2.23.0)\n",
      "Requirement already satisfied: numpy in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from torchtext) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from torch==1.8.0->torchtext) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from requests->torchtext) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/michaelfeldman/opt/anaconda3/lib/python3.7/site-packages (from requests->torchtext) (1.25.11)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /Users/michaelfeldman/opt/anaconda3/include/python3.7m/UNKNOWN\n",
      "sysconfig: /Users/michaelfeldman/opt/anaconda3/include/python3.7m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('initial_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_orig</th>\n",
       "      <th>name</th>\n",
       "      <th>license</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>date_orig</th>\n",
       "      <th>inspection_type_orig</th>\n",
       "      <th>results_orig</th>\n",
       "      <th>violations_orig</th>\n",
       "      <th>id_re</th>\n",
       "      <th>date_re</th>\n",
       "      <th>results_re</th>\n",
       "      <th>time_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2362749</td>\n",
       "      <td>DANIEL WILLIAM HALE</td>\n",
       "      <td>66311</td>\n",
       "      <td>School</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>38. INSECTS, RODENTS, &amp; ANIMALS NOT PRESENT - ...</td>\n",
       "      <td>2363154</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2009301</td>\n",
       "      <td>DANIEL WILLIAM HALE</td>\n",
       "      <td>66311</td>\n",
       "      <td>School</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2009714</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1734408</td>\n",
       "      <td>DANIEL WILLIAM HALE</td>\n",
       "      <td>66311</td>\n",
       "      <td>School</td>\n",
       "      <td>2016-03-18</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>13. NO EVIDENCE OF RODENT OR INSECT INFESTATIO...</td>\n",
       "      <td>1734665</td>\n",
       "      <td>2016-03-23</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1386146</td>\n",
       "      <td>DANIEL WILLIAM HALE</td>\n",
       "      <td>66311</td>\n",
       "      <td>School</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>13. NO EVIDENCE OF RODENT OR INSECT INFESTATIO...</td>\n",
       "      <td>1386157</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>Pass</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2463620</td>\n",
       "      <td>DAYGLOW</td>\n",
       "      <td>2749526</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>2. CITY OF CHICAGO FOOD SERVICE SANITATION CER...</td>\n",
       "      <td>2463913</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>Pass w/ Conditions</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_orig                 name  license facility_type  date_orig  \\\n",
       "8   2362749  DANIEL WILLIAM HALE    66311        School 2020-02-24   \n",
       "21  2009301  DANIEL WILLIAM HALE    66311        School 2017-03-27   \n",
       "34  1734408  DANIEL WILLIAM HALE    66311        School 2016-03-18   \n",
       "39  1386146  DANIEL WILLIAM HALE    66311        School 2015-05-20   \n",
       "65  2463620              DAYGLOW  2749526    Restaurant 2020-12-10   \n",
       "\n",
       "   inspection_type_orig results_orig  \\\n",
       "8               Canvass         Fail   \n",
       "21              Canvass         Fail   \n",
       "34              Canvass         Fail   \n",
       "39              Canvass         Fail   \n",
       "65              License         Fail   \n",
       "\n",
       "                                      violations_orig    id_re    date_re  \\\n",
       "8   38. INSECTS, RODENTS, & ANIMALS NOT PRESENT - ...  2363154 2020-03-03   \n",
       "21  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  2009714 2017-04-04   \n",
       "34  13. NO EVIDENCE OF RODENT OR INSECT INFESTATIO...  1734665 2016-03-23   \n",
       "39  13. NO EVIDENCE OF RODENT OR INSECT INFESTATIO...  1386157 2015-05-22   \n",
       "65  2. CITY OF CHICAGO FOOD SERVICE SANITATION CER...  2463913 2020-12-17   \n",
       "\n",
       "            results_re  time_between  \n",
       "8                 Pass            -8  \n",
       "21                Pass            -8  \n",
       "34                Pass            -5  \n",
       "39                Pass            -2  \n",
       "65  Pass w/ Conditions            -7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Pass w/ Conditions' to 'Pass', and change target to 0/1 numeric\n",
    "results_dict = {'Pass': 0, 'Fail': 1}\n",
    "df['results_re'] = df['results_re'].str.replace('Pass w/ Conditions', 'Pass')\n",
    "df['results_re'] = df['results_re'].apply(lambda x: results_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into feature & target, and then into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by inspection date\n",
    "# Training set will include initial 80% of inspections\n",
    "sorted_df = df.sort_values(by=['date_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_orig</th>\n",
       "      <th>name</th>\n",
       "      <th>license</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>date_orig</th>\n",
       "      <th>inspection_type_orig</th>\n",
       "      <th>results_orig</th>\n",
       "      <th>violations_orig</th>\n",
       "      <th>id_re</th>\n",
       "      <th>date_re</th>\n",
       "      <th>results_re</th>\n",
       "      <th>time_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220538</th>\n",
       "      <td>104236</td>\n",
       "      <td>TEMPO CAFE</td>\n",
       "      <td>80916</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>104243</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494292</th>\n",
       "      <td>67738</td>\n",
       "      <td>MICHAEL'S ON MAIN CAFE</td>\n",
       "      <td>2008948</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>124279</td>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379705</th>\n",
       "      <td>118297</td>\n",
       "      <td>MAXWELL STREET DEPOT INC.</td>\n",
       "      <td>18135</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>118308</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491825</th>\n",
       "      <td>80208</td>\n",
       "      <td>Dunkin Donuts</td>\n",
       "      <td>2013340</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>80233</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263231</th>\n",
       "      <td>67741</td>\n",
       "      <td>CITGO</td>\n",
       "      <td>2013296</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n",
       "      <td>176270</td>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>0</td>\n",
       "      <td>-43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_orig                       name  license  facility_type  date_orig  \\\n",
       "220538  104236                 TEMPO CAFE    80916     Restaurant 2010-01-04   \n",
       "494292   67738     MICHAEL'S ON MAIN CAFE  2008948     Restaurant 2010-01-04   \n",
       "379705  118297  MAXWELL STREET DEPOT INC.    18135     Restaurant 2010-01-05   \n",
       "491825   80208              Dunkin Donuts  2013340     Restaurant 2010-01-05   \n",
       "263231   67741                      CITGO  2013296  Grocery Store 2010-01-05   \n",
       "\n",
       "       inspection_type_orig results_orig  \\\n",
       "220538              Canvass         Fail   \n",
       "494292              License         Fail   \n",
       "379705            Complaint         Fail   \n",
       "491825              License         Fail   \n",
       "263231              License         Fail   \n",
       "\n",
       "                                          violations_orig   id_re    date_re  \\\n",
       "220538  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  104243 2010-01-12   \n",
       "494292  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  124279 2010-01-19   \n",
       "379705  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...  118308 2010-01-12   \n",
       "491825  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...   80233 2010-02-05   \n",
       "263231  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...  176270 2010-02-17   \n",
       "\n",
       "        results_re  time_between  \n",
       "220538           0            -8  \n",
       "494292           0           -15  \n",
       "379705           0            -7  \n",
       "491825           1           -31  \n",
       "263231           0           -43  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['results_re']\n",
    "target = sorted_df[target_col]\n",
    "\n",
    "cols_to_exclude = ['name', 'id_orig', 'id_re', 'license']\n",
    "feature_cols = [col for col in sorted_df.columns if (col not in cols_to_exclude and col not in target_col)]\n",
    "features = sorted_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>results_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220538</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494292</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379705</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491825</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263231</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        results_re\n",
       "220538           0\n",
       "494292           0\n",
       "379705           0\n",
       "491825           1\n",
       "263231           0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility_type</th>\n",
       "      <th>date_orig</th>\n",
       "      <th>inspection_type_orig</th>\n",
       "      <th>results_orig</th>\n",
       "      <th>violations_orig</th>\n",
       "      <th>date_re</th>\n",
       "      <th>time_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220538</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494292</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379705</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491825</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263231</th>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>-43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        facility_type  date_orig inspection_type_orig results_orig  \\\n",
       "220538     Restaurant 2010-01-04              Canvass         Fail   \n",
       "494292     Restaurant 2010-01-04              License         Fail   \n",
       "379705     Restaurant 2010-01-05            Complaint         Fail   \n",
       "491825     Restaurant 2010-01-05              License         Fail   \n",
       "263231  Grocery Store 2010-01-05              License         Fail   \n",
       "\n",
       "                                          violations_orig    date_re  \\\n",
       "220538  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "494292  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-19   \n",
       "379705  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "491825  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-02-05   \n",
       "263231  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -... 2010-02-17   \n",
       "\n",
       "        time_between  \n",
       "220538            -8  \n",
       "494292           -15  \n",
       "379705            -7  \n",
       "491825           -31  \n",
       "263231           -43  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't shuffle data before splitting\n",
    "train_feat, test_feat, train_targ, test_targ = train_test_split(features, target, test_size=0.2,\n",
    "                                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility_type</th>\n",
       "      <th>date_orig</th>\n",
       "      <th>inspection_type_orig</th>\n",
       "      <th>results_orig</th>\n",
       "      <th>violations_orig</th>\n",
       "      <th>date_re</th>\n",
       "      <th>time_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220538</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494292</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379705</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491825</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263231</th>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>License</td>\n",
       "      <td>Fail</td>\n",
       "      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>-43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        facility_type  date_orig inspection_type_orig results_orig  \\\n",
       "220538     Restaurant 2010-01-04              Canvass         Fail   \n",
       "494292     Restaurant 2010-01-04              License         Fail   \n",
       "379705     Restaurant 2010-01-05            Complaint         Fail   \n",
       "491825     Restaurant 2010-01-05              License         Fail   \n",
       "263231  Grocery Store 2010-01-05              License         Fail   \n",
       "\n",
       "                                          violations_orig    date_re  \\\n",
       "220538  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "494292  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-19   \n",
       "379705  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-01-12   \n",
       "491825  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN... 2010-02-05   \n",
       "263231  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -... 2010-02-17   \n",
       "\n",
       "        time_between  \n",
       "220538            -8  \n",
       "494292           -15  \n",
       "379705            -7  \n",
       "491825           -31  \n",
       "263231           -43  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.79% reinspections fail in training set\n"
     ]
    }
   ],
   "source": [
    "pct_fail = len(train_targ[train_targ['results_re'] == 1]) / len(train_targ)\n",
    "print(f'{pct_fail*100:.2f}% reinspections fail in training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = ['violations_orig']\n",
    "train_feat_txt = train_feat[text_col].astype(str)\n",
    "test_feat_txt = test_feat[text_col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violations_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220538</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494292</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379705</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491825</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263231</th>\n",
       "      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          violations_orig\n",
       "220538  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "494292  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "379705  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "491825  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "263231  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab using training set only!!!!\n",
    "for idx, text in train_feat_txt.itertuples():\n",
    "    counter.update(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'the']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('I like the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure what the min frequency should be\n",
    "# Min freq = 1 -> 50768 vocab length\n",
    "# Min freq = 50 -> 2942\n",
    "# Min freq = 100 -> 2211\n",
    "# Min freq = 250 -> 1481\n",
    "# Min freq = 500 -> 1107\n",
    "# Min freq = 1000 -> 806\n",
    "MIN_FREQ = 500\n",
    "vocab = Vocab(counter, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1086"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_into_bow(data, voc=vocab):\n",
    "    bow = torch.zeros((len(data), len(voc) + 1))\n",
    "    labels = torch.zeros((len(data), 1))\n",
    "    for i, (label, text) in enumerate(data):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        line_vocab = Vocab(counter)\n",
    "        tot_freqs = sum(line_vocab.freqs.values())\n",
    "        labels[i] = label\n",
    "        for token in line_vocab.freqs:\n",
    "            bow[i, voc.stoi[token]] = line_vocab.freqs[token] / tot_freqs  # Using relative frequencies\n",
    "            bow[i, -1] = tot_freqs\n",
    "    \n",
    "    return (labels, bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Create CBOW features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORS_CACHE_DIR = './.vector_cache'\n",
    "DIM_GLOVE = 300\n",
    "\n",
    "glove = GloVe('6B',cache=VECTORS_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_into_cbow(data):\n",
    "    cbow = torch.zeros((len(data), DIM_GLOVE))\n",
    "    labels = torch.zeros((len(data), 1))\n",
    "    for i, (label, text) in enumerate(data):\n",
    "        counter = Counter()\n",
    "        counter.update(tokenizer(text))\n",
    "        tokens = list(Vocab(counter).freqs)\n",
    "        vecs = glove.get_vecs_by_tokens(tokens)\n",
    "        cbow[i] = torch.mean(vecs, axis=0)\n",
    "        labels[i] = label\n",
    "    return (labels, cbow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer to get ngrams (this was the most intuitive tool I could find...)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_rows_by_row_sum(arr):\n",
    "    return np.nan_to_num(\n",
    "            np.divide(arr, arr.sum(axis=1)[:, None]),\n",
    "            nan=0  # Small number of ngram rows are all zeroes; don't divide row by 0 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=MIN_FREQ, ngram_range=(2,2))\n",
    "corpus = train_feat_txt['violations_orig'].to_list()\n",
    "vocab_ngrams = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm not sure how to get this to include document length, since\n",
    "#I had to alter the BOW collate function so it would work\n",
    "#with the dataloader\n",
    "\n",
    "def collate_into_ngrams(data, voc=vocab_ngrams):\n",
    "    ngrams = torch.zeros((len(data), voc.shape[1]))\n",
    "    labels = torch.zeros((len(data), 1))\n",
    "    for i, (label, text) in enumerate(data):\n",
    "        X_batch = vectorizer.transform([text])\n",
    "        ngram_arr = X_batch.toarray()\n",
    "        ngram_arr = divide_rows_by_row_sum(ngram_arr)\n",
    "        ngrams[i, :] = torch.tensor(ngram_arr)\n",
    "        labels[i] = label\n",
    "    \n",
    "    return (labels, ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train set into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_feat_txt, train_targ,\n",
    "                                                    test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversample on target vector\n",
    "train_targ_reset = train_y.reset_index().drop('index', axis=1)\n",
    "train_targ_fail = train_targ_reset[train_targ_reset['results_re'] == 1]\n",
    "size_diff = train_targ_reset.shape[0] - train_targ_fail.shape[0]\n",
    "train_resample = resample(train_targ_fail, n_samples = size_diff, replace=True)\n",
    "train_targ_all = pd.concat([train_targ_reset, train_resample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class InspectionsDataset(Dataset):\n",
    "    def __init__(self, features_df, target_df):\n",
    "\n",
    "        self.features_text = features_df['violations_orig']\n",
    "        self.labels = target_df['results_re']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features_text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.features_text.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        return (label, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then resample features\n",
    "train_x_reset = train_x.reset_index().drop('index', axis=1)\n",
    "train_x_resample = train_x_reset.iloc[train_targ_all.index]\n",
    "\n",
    "#and convert to dataset object\n",
    "inspections_train = InspectionsDataset(train_x_resample, train_targ_all)\n",
    "inspections_val = InspectionsDataset(val_x, val_y)\n",
    "inspections_test = InspectionsDataset(test_feat_txt, test_targ)\n",
    "\n",
    "#these can all now be fed into DataLoaders with the proper collate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violations_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220538</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494292</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379705</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491825</th>\n",
       "      <td>18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263231</th>\n",
       "      <td>2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298536</th>\n",
       "      <td>3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345820</th>\n",
       "      <td>3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274648</th>\n",
       "      <td>3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111325</th>\n",
       "      <td>3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29765 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          violations_orig\n",
       "220538  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "494292  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "379705  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "491825  18. NO EVIDENCE OF RODENT OR INSECT OUTER OPEN...\n",
       "263231  2. FACILITIES TO MAINTAIN PROPER TEMPERATURE -...\n",
       "...                                                   ...\n",
       "298536  3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...\n",
       "345820  3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...\n",
       "4686    3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...\n",
       "274648  3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...\n",
       "111325  3. MANAGEMENT, FOOD EMPLOYEE AND CONDITIONAL E...\n",
       "\n",
       "[29765 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>results_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220538</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494292</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379705</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491825</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263231</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298536</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345820</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274648</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111325</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29765 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        results_re\n",
       "220538           0\n",
       "494292           0\n",
       "379705           0\n",
       "491825           1\n",
       "263231           0\n",
       "...            ...\n",
       "298536           0\n",
       "345820           1\n",
       "4686             0\n",
       "274648           0\n",
       "111325           0\n",
       "\n",
       "[29765 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text and label in 1 file\n",
    "df_train = pd.concat([train_x_resample, train_targ_all], axis=1)\n",
    "df_valid = pd.concat([val_x, val_y], axis=1)\n",
    "df_test = pd.concat([test_feat_txt, test_targ], axis=1)\n",
    "\n",
    "# Create training file to build vocab (includes train+valid sets)\n",
    "train_vocab = pd.concat([train_feat_txt, train_targ], axis=1)\n",
    "\n",
    "# df_train.to_csv('train.csv', index=False)\n",
    "# df_valid.to_csv('valid.csv', index=False)\n",
    "# df_test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set CUDA settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(\"Using cuda.\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(\"Using cpu.\")\n",
    "    \n",
    "random.seed(30255)\n",
    "np.random.seed(30255)\n",
    "torch.manual_seed(30255)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(30255)\n",
    "    \n",
    "COLAB = False\n",
    "#COLAB = True\n",
    "if COLAB:\n",
    "    from google.colab import drive \n",
    "    drive.mount('/content/gdrive')\n",
    "    PATH = \"gdrive/My Drive/advanced_ml/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assisted by: https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0<br>\n",
    "https://www.kaggle.com/swarnabha/pytorch-text-classification-torchtext-lstm<br>\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field, LabelField, TabularDataset, BucketIterator, Example, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Field objects to process the text data\n",
    "# they will include info for how to convert the text to tensors\n",
    "TEXT = Field(tokenize='basic_english', lower=True, batch_first=True)\n",
    "LABEL = LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://gist.github.com/lextoumbourou/8f90313cbc3598ffbabeeaa1741a11c8\n",
    "# to use DataFrame as a Data source\n",
    "class DataFrameDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.results_re if not is_test else None\n",
    "            text = row.violations_orig\n",
    "            examples.append(Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.violations_orig)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        data_field = fields\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
    "        if val_df is not None:\n",
    "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset objects using the train and validation dataframes\n",
    "fields = [('violations_orig', TEXT), ('results_re', LABEL)]\n",
    "train_ds, val_ds = DataFrameDataset.splits(fields, train_df=df_train, val_df=df_valid)\n",
    "\n",
    "# Create Dataset object on original train df (that includes train and validation\n",
    "# sets), so we can reproduce original vocab\n",
    "# train_vocab_ds = DataFrameDataset.splits(fields, train_df=train_vocab)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocab using original training set\n",
    "# TEXT.build_vocab(train_vocab_ds, vectors = 'glove.6B.300d', min_freq=MIN_FREQ)\n",
    "TEXT.build_vocab(train_ds, vectors = 'glove.6B.300d', min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of new vocab is... 1086\n",
      "Length of original vocab is... 1086\n"
     ]
    }
   ],
   "source": [
    "# Make sure new vocab is the same as original vocab\n",
    "print('Length of new vocab is...', len(TEXT.vocab.itos))\n",
    "print('Length of original vocab is...', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "    (train_ds, val_ds),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.violations_orig),\n",
    "#     sort_within_batch = True,\n",
    "    device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
       "        ...,\n",
       "        [ 0.2763,  0.2984,  0.0830,  ..., -0.1555, -0.3882, -0.7194],\n",
       "        [ 0.3941, -0.0404,  0.4790,  ...,  0.0949, -0.4145,  0.2473],\n",
       "        [-0.3772, -0.1181,  0.0712,  ..., -0.2140, -0.2401,  0.6279]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained embeddings\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero out the initial weights of the unknown and padding tokens\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 50\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.violations_orig).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.results_re)\n",
    "        acc = binary_accuracy(predictions, batch.results_re)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            print(f'At iteration {i} the training accuracy is {acc:.3f}.')\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.violations_orig).squeeze(1)\n",
    "            loss = criterion(predictions, batch.results_re)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.results_re)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-63951c7b2289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-210-e608efe27ab5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_re\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNNLM(nn.Module):\n",
    "    \"\"\" Container module with an linear encoder/embedding, an RNN module, and a linear decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, vocab_size, embedding_dim, hidden_dim, num_layers, \n",
    "                 output_dim=1, dropout=0.5):\n",
    "        ''' Initialize model parameters corresponding to ---\n",
    "            - embedding layer\n",
    "            - recurrent neural network layer---one of LSTM, GRU, or RNN---with \n",
    "              optionally more than one layer\n",
    "            - linear layer to map from hidden vector to the vocabulary\n",
    "            - optionally, dropout layers.  Dropout layers can be placed after \n",
    "              the embedding layer or/and after the RNN layer. Dropout within\n",
    "              an RNN is only applied when there are two or more num_layers.\n",
    "            - optionally, initialize the model parameters.\n",
    "            \n",
    "            The arguments are:\n",
    "            \n",
    "            rnn_type: One of 'LSTM', 'GRU', 'RNN_TANH', 'RNN_RELU'\n",
    "            vocab_size: size of vocabulary\n",
    "            embedding_dim: size of an embedding vector\n",
    "            hidden_dim: size of hidden/state vector in RNN\n",
    "            num_layers: number of layers in RNN\n",
    "            dropout: dropout probability.\n",
    "            \n",
    "        '''\n",
    "        super(RNNLM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if rnn_type == 'LSTM':\n",
    "            self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                                num_layers=num_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        self.out = nn.Sigmoid\n",
    "        \n",
    "\n",
    "    def forward(self, batch, hidden0=None):\n",
    "        ''' \n",
    "        Run forward propagation for a given minibatch of inputs using\n",
    "        hidden0 as the initial hidden state.\n",
    "\n",
    "        In LSTMs hidden0 = (h_0, c_0). \n",
    "\n",
    "        The output of the RNN includes the hidden vector hiddenn = (h_n, c_n).\n",
    "        Return this as well so that it can be used to initialize the next\n",
    "        batch.\n",
    "        \n",
    "        Unlike previous homework sets do not apply softmax or logsoftmax here, since we'll use\n",
    "        the more efficient CrossEntropyLoss.  See \n",
    "        https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html.\n",
    "        '''\n",
    "        emb = self.embedding(batch)\n",
    "        output, hidden = self.lstm(emb, hidden0)\n",
    "        return self.out(nn.self.linear(output))  # not outputting hidden state; each example is a different inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAD_CLIP = 1\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "def train_an_epoch(dataloader):\n",
    "    model.train() # Sets the module in training mode.\n",
    "    log_interval = 500\n",
    "\n",
    "    for (_, ((text, label), _)) in enumerate(dataloader):\n",
    "        print('text is...', text)\n",
    "        model.zero_grad()\n",
    "        probs = model(text)\n",
    "        loss = loss_function(probs, label)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "#         if idx % log_interval == 0 and idx > 0:\n",
    "#             print(f'At iteration {idx} the loss is {loss:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            outputs = model(text)\n",
    "            predicted = torch.round(outputs)\n",
    "            #predicted = torch.max(outputs.data, 1)[1]\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    \n",
    "    print(\"Total: {}, correct: {}\".format(total, correct))\n",
    "    return(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text is... tensor([[1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103,\n",
      "         1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103,\n",
      "         1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103,\n",
      "         1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103,\n",
      "         1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103, 1103,\n",
      "         1103, 1103, 1103, 1103]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-33fc136834e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_an_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-cfb722042464>\u001b[0m in \u001b[0;36mtrain_an_epoch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text is...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-0fff4549fd36>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, hidden0)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstable\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         '''\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# not outputting hidden state; each example is a different inspection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "num_labels = 2\n",
    "vocab_size = len(vocab) + 1\n",
    "embedding_size = 50\n",
    "\n",
    "model = RNNLM(\"LSTM\", vocab_size, embedding_size, embedding_size, num_layers=2,\n",
    "              dropout=0.5)\n",
    "EPOCHS = 3 # epoch\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "#reset/clear out model just in case\n",
    "for layer in model.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        layer.reset_parameters()\n",
    "\n",
    "\n",
    "accuracies=[]\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_an_epoch(train_dataloader)\n",
    "    accuracy = get_accuracy(valid_dataloader)\n",
    "    accuracies.append(accuracy)\n",
    "    print()\n",
    "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
    "    print()\n",
    "    \n",
    "plt.plot(range(1, EPOCHS+1), accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloaders\n",
    "train_dataloader = DataLoader(inspections_train, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                                collate_fn=collate_into_cbow)\n",
    "val_dataloader = DataLoader(inspections_val, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_cbow)\n",
    "test_dataloader = DataLoader(inspections_test, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloaders\n",
    "train_dataloader = DataLoader(inspections_train, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                                collate_fn=collate_into_ngrams)\n",
    "val_dataloader = DataLoader(inspections_val, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_ngrams)\n",
    "test_dataloader = DataLoader(inspections_test, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                collate_fn=collate_into_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
